{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Neural Network from Scratch with NumPy\n",
        "\n",
        "This notebook implements and trains a fully-connected feedforward neural network from scratch using only NumPy.\n",
        "\n",
        "## Project Overview\n",
        "- Implementing forward and backward propagation manually\n",
        "- Training on Fashion-MNIST and CIFAR-10 datasets\n",
        "- Experiment tracking with Weights & Biases (WandB)\n",
        "- Comparing different architectures, optimizers, and hyperparameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Import our custom modules from the refactored package\n",
        "from src.data.loaders import load_dataset, one_hot_encode, train_val_split\n",
        "from src.evaluation.metrics import accuracy, confusion_matrix_counts, classification_report_dict\n",
        "from src.models.feedforward import FeedForwardNN, NetworkConfig\n",
        "from src.optimizers import Optimizer, OptimizerConfig\n",
        "from src.training.trainer import TrainingConfig, train_model\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Dataset\n",
        "\n",
        "We'll start with Fashion-MNIST dataset, which is a good starting point for testing our implementation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Fashion-MNIST dataset\n",
        "print(\"Loading Fashion-MNIST dataset...\")\n",
        "X_train_raw, y_train_raw, X_test, y_test = load_dataset(\"fashion_mnist\", source=\"keras\")\n",
        "\n",
        "# Create validation split\n",
        "X_train, y_train, X_val, y_val = train_val_split(X_train_raw, y_train_raw, validation_split=0.1)\n",
        "\n",
        "num_classes = int(np.max(y_train_raw)) + 1\n",
        "input_size = X_train.shape[1]\n",
        "\n",
        "print(f\"Training set: {X_train.shape}\")\n",
        "print(f\"Validation set: {X_val.shape}\")\n",
        "print(f\"Test set: {X_test.shape}\")\n",
        "print(f\"Input size: {input_size}\")\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train_onehot = one_hot_encode(y_train, num_classes)\n",
        "y_val_onehot = one_hot_encode(y_val, num_classes)\n",
        "y_test_onehot = one_hot_encode(y_test, num_classes)\n",
        "\n",
        "print(\"\\nLabels one-hot encoded!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Initialize and Train Model\n",
        "\n",
        "Let's create a simple neural network and train it on Fashion-MNIST.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure the network and optimizer\n",
        "network_config = NetworkConfig(\n",
        "    input_size=input_size,\n",
        "    hidden_sizes=[128, 64],\n",
        "    output_size=num_classes,\n",
        "    activation=\"relu\",\n",
        "    output_activation=\"softmax\",\n",
        "    weight_init=\"he\",\n",
        "    l2_coeff=1e-4,\n",
        ")\n",
        "\n",
        "optimizer_config = OptimizerConfig(\n",
        "    optimizer_type=\"adam\",\n",
        "    learning_rate=1e-3,\n",
        "    weight_decay=0.0,\n",
        ")\n",
        "\n",
        "model = FeedForwardNN(network_config)\n",
        "optimizer = Optimizer(optimizer_config)\n",
        "train_config = TrainingConfig(batch_size=32, num_epochs=20, loss=\"cross_entropy\", use_wandb=False)\n",
        "\n",
        "print(\"Model created successfully!\")\n",
        "print(f\"Number of layers: {model.num_layers}\")\n",
        "print(f\"Layer sizes: {model.layer_sizes}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model\n",
        "print(\"Starting training...\")\n",
        "history = train_model(\n",
        "    model,\n",
        "    optimizer,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    X_val,\n",
        "    y_val,\n",
        "    config=train_config,\n",
        ")\n",
        "\n",
        "print(\"\\nTraining completed!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Evaluate Model\n",
        "\n",
        "Let's evaluate the trained model on the test set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate on test set\n",
        "test_probabilities = model.predict_proba(X_test)\n",
        "test_accuracy = accuracy(y_test_onehot, test_probabilities)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix_counts(y_test_onehot, test_probabilities)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Classification report\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "report = classification_report_dict(y_test_onehot, test_probabilities, class_names=class_names)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(f\"Overall Accuracy: {report['accuracy']:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Plot Training Curves\n",
        "\n",
        "Visualize the training and validation loss/accuracy over epochs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training curves\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Loss curve\n",
        "axes[0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
        "axes[0].plot(history['val_loss'], label='Validation Loss', linewidth=2)\n",
        "axes[0].set_xlabel('Epoch', fontsize=12)\n",
        "axes[0].set_ylabel('Loss', fontsize=12)\n",
        "axes[0].set_title('Training and Validation Loss', fontsize=14)\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Accuracy curve\n",
        "axes[1].plot(history['train_accuracy'], label='Train Accuracy', linewidth=2)\n",
        "axes[1].plot(history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
        "axes[1].set_xlabel('Epoch', fontsize=12)\n",
        "axes[1].set_ylabel('Accuracy', fontsize=12)\n",
        "axes[1].set_title('Training and Validation Accuracy', fontsize=14)\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Experiment with Different Hyperparameters\n",
        "\n",
        "Now let's experiment with different configurations to see how they affect performance.\n",
        "\n",
        "### Experiment 1: Different Optimizers\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare different optimizers\n",
        "optimizers = ['sgd', 'adam', 'rmsprop']\n",
        "optimizer_results = {}\n",
        "\n",
        "for opt in optimizers:\n",
        "    print(f\"\\nTraining with {opt.upper()} optimizer...\")\n",
        "\n",
        "    net_cfg = NetworkConfig(\n",
        "        input_size=input_size,\n",
        "        hidden_sizes=[128, 64],\n",
        "        output_size=num_classes,\n",
        "        activation='relu',\n",
        "        output_activation='softmax',\n",
        "        weight_init='he',\n",
        "        l2_coeff=1e-4,\n",
        "    )\n",
        "    model_opt = FeedForwardNN(net_cfg)\n",
        "    opt_cfg = OptimizerConfig(optimizer_type=opt, learning_rate=1e-3)\n",
        "    optimizer_instance = Optimizer(opt_cfg)\n",
        "    train_cfg = TrainingConfig(batch_size=32, num_epochs=10, loss='cross_entropy', use_wandb=False)\n",
        "\n",
        "    history_opt = train_model(model_opt, optimizer_instance, X_train, y_train, X_val, y_val, config=train_cfg)\n",
        "\n",
        "    test_prob = model_opt.predict_proba(X_test)\n",
        "    test_acc = accuracy(y_test_onehot, test_prob)\n",
        "\n",
        "    optimizer_results[opt] = {\n",
        "        'history': history_opt,\n",
        "        'test_accuracy': test_acc\n",
        "    }\n",
        "\n",
        "    print(f\"{opt.upper()} - Test Accuracy: {test_acc:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot comparison of optimizers\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "for opt in optimizers:\n",
        "    plt.plot(optimizer_results[opt]['history']['val_loss'], label=f'{opt.upper()}', linewidth=2)\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Validation Loss', fontsize=12)\n",
        "plt.title('Validation Loss Comparison', fontsize=14)\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "for opt in optimizers:\n",
        "    plt.plot(optimizer_results[opt]['history']['val_accuracy'], label=f'{opt.upper()}', linewidth=2)\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Validation Accuracy', fontsize=12)\n",
        "plt.title('Validation Accuracy Comparison', fontsize=14)\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nFinal Test Accuracies:\")\n",
        "for opt in optimizers:\n",
        "    print(f\"{opt.upper()}: {optimizer_results[opt]['test_accuracy']:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Experiment 2: Different Activation Functions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare different activation functions\n",
        "activations = ['relu', 'sigmoid', 'tanh']\n",
        "activation_results = {}\n",
        "\n",
        "for act in activations:\n",
        "    print(f\"\\nTraining with {act.upper()} activation...\")\n",
        "\n",
        "    weight_init = 'he' if act == 'relu' else 'xavier'\n",
        "    net_cfg = NetworkConfig(\n",
        "        input_size=input_size,\n",
        "        hidden_sizes=[128, 64],\n",
        "        output_size=num_classes,\n",
        "        activation=act,\n",
        "        output_activation='softmax',\n",
        "        weight_init=weight_init,\n",
        "        l2_coeff=1e-4,\n",
        "    )\n",
        "    model_act = FeedForwardNN(net_cfg)\n",
        "    opt_cfg = OptimizerConfig(optimizer_type='adam', learning_rate=1e-3)\n",
        "    optimizer_instance = Optimizer(opt_cfg)\n",
        "    train_cfg = TrainingConfig(batch_size=32, num_epochs=10, loss='cross_entropy', use_wandb=False)\n",
        "\n",
        "    history_act = train_model(model_act, optimizer_instance, X_train, y_train, X_val, y_val, config=train_cfg)\n",
        "\n",
        "    test_prob = model_act.predict_proba(X_test)\n",
        "    test_acc = accuracy(y_test_onehot, test_prob)\n",
        "\n",
        "    activation_results[act] = {\n",
        "        'history': history_act,\n",
        "        'test_accuracy': test_acc\n",
        "    }\n",
        "\n",
        "    print(f\"{act.upper()} - Test Accuracy: {test_acc:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. WandB Integration for Experiment Tracking\n",
        "\n",
        "To use WandB for comprehensive experiment tracking, uncomment and modify the code below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example WandB sweep configuration\n",
        "# Uncomment and run this cell to start a WandB sweep\n",
        "\n",
        "# import wandb\n",
        "# \n",
        "# wandb.init(project=\"numpy-neural-network\", \n",
        "#            name=\"fashion-mnist-experiment\",\n",
        "#            config={\n",
        "#                \"input_size\": input_size,\n",
        "#                \"hidden_sizes\": [128, 64],\n",
        "#                \"output_size\": num_classes,\n",
        "#                \"activation\": \"relu\",\n",
        "#                \"loss\": \"cross_entropy\",\n",
        "#                \"learning_rate\": 0.001,\n",
        "#                \"optimizer\": \"adam\",\n",
        "#                \"l2_coeff\": 0.0001,\n",
        "#                \"weight_init\": \"he\",\n",
        "#                \"batch_size\": 32,\n",
        "#                \"num_epochs\": 20,\n",
        "#                \"dataset\": \"fashion-mnist\"\n",
        "#            })\n",
        "# \n",
        "# model = FFNN(\n",
        "#     input_size=input_size,\n",
        "#     hidden_sizes=[128, 64],\n",
        "#     output_size=num_classes,\n",
        "#     activation='relu',\n",
        "#     loss='cross_entropy',\n",
        "#     learning_rate=wandb.config.learning_rate,\n",
        "#     optimizer=wandb.config.optimizer,\n",
        "#     l2_coeff=wandb.config.l2_coeff,\n",
        "#     weight_init=wandb.config.weight_init,\n",
        "#     batch_size=wandb.config.batch_size,\n",
        "#     num_epochs=wandb.config.num_epochs\n",
        "# )\n",
        "# \n",
        "# history = train_model(model, optimizer, X_train, y_train, X_val, y_val, config=train_cfg)\n",
        "# \n",
        "# # Log final test accuracy\n",
        "# test_pred = model.predict(X_test)\n",
        "# test_acc = accuracy(y_test_onehot, test_pred)\n",
        "# wandb.log({\"test_accuracy\": test_acc})\n",
        "# \n",
        "# wandb.finish()\n",
        "\n",
        "print(\"WandB integration example (commented out). Uncomment to use.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. CIFAR-10 Experiment (Optional)\n",
        "\n",
        "You can also experiment with CIFAR-10 dataset. Note that it requires more computational resources.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to load and train on CIFAR-10\n",
        "# Note: CIFAR-10 has larger images (32x32x3 = 3072 features) and will take longer to train\n",
        "\n",
        "# print(\"Loading CIFAR-10 dataset...\")\n",
        "# X_train_cifar_raw, y_train_cifar_raw, X_test_cifar, y_test_cifar = load_dataset(\"cifar10\", source=\"keras\")\n",
        "# X_train_cifar, y_train_cifar, X_val_cifar, y_val_cifar = train_val_split(X_train_cifar_raw, y_train_cifar_raw, validation_split=0.1)\n",
        "# \n",
        "# num_classes_cifar = int(np.max(y_train_cifar_raw)) + 1\n",
        "# input_size_cifar = X_train_cifar.shape[1]\n",
        "# \n",
        "# print(f\"CIFAR-10 Training set: {X_train_cifar.shape}\")\n",
        "# print(f\"CIFAR-10 Input size: {input_size_cifar}\")\n",
        "# \n",
        "# # One-hot encode labels for evaluation convenience\n",
        "# y_test_cifar_onehot = one_hot_encode(y_test_cifar, num_classes_cifar)\n",
        "# \n",
        "# # Create and train model for CIFAR-10\n",
        "# network_config_cifar = NetworkConfig(\n",
        "#     input_size=input_size_cifar,\n",
        "#     hidden_sizes=[256, 128, 64],  # Larger network for CIFAR-10\n",
        "#     output_size=num_classes_cifar,\n",
        "#     activation='relu',\n",
        "#     output_activation='softmax',\n",
        "#     weight_init='he',\n",
        "#     l2_coeff=1e-4,\n",
        "# )\n",
        "# model_cifar = FeedForwardNN(network_config_cifar)\n",
        "# optimizer_config_cifar = OptimizerConfig(optimizer_type='adam', learning_rate=1e-3)\n",
        "# optimizer_cifar = Optimizer(optimizer_config_cifar)\n",
        "# train_config_cifar = TrainingConfig(batch_size=64, num_epochs=30, loss='cross_entropy', use_wandb=False)\n",
        "# \n",
        "# print(\"Training on CIFAR-10...\")\n",
        "# history_cifar = train_model(model_cifar, optimizer_cifar, X_train_cifar, y_train_cifar, X_val_cifar, y_val_cifar, config=train_config_cifar)\n",
        "# \n",
        "# # Evaluate\n",
        "# test_prob_cifar = model_cifar.predict_proba(X_test_cifar)\n",
        "# test_acc_cifar = accuracy(y_test_cifar_onehot, test_prob_cifar)\n",
        "# print(f\"CIFAR-10 Test Accuracy: {test_acc_cifar:.4f}\")\n",
        "\n",
        "print(\"CIFAR-10 experiment code (commented out). Uncomment to run.\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
